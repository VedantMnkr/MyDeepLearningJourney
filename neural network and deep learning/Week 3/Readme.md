##Week 3

This week was focused on more the architecture side that how a generic neural network looks and its other components like forward propogation, backward propogation
activation fucntions and when to use which one, and more.

And in the programming assignment , we were demonstrated why a deep learning model is required over a linear model.
